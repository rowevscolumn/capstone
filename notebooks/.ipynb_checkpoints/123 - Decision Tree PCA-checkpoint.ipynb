{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\sourc\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier #Import scikit-Tree For Decision Tree\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.metrics import classification_report,confusion_matrix #import Confusion Matrix\n",
    "from sklearn.model_selection import train_test_split # Splitting the data\n",
    "from sklearn import preprocessing # Normalizing\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from IPython.display import Image  \n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_o = pd.read_csv(\"../data/processed/data_allcolumns.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "x = df_o.values #returns a numpy array\n",
    "col = df_o.columns\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_n = pd.DataFrame(x_scaled, columns = col)\n",
    "\n",
    "# df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    22532\n",
       "0    22532\n",
       "Name: isFirstDown, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df_o[df_o['isFirstDown']==0]\n",
    "df_minority = df_o[df_o['isFirstDown']==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,                  # sample with replacement\n",
    "                                 n_samples=len(df_majority),    # to match majority class\n",
    "                                 random_state=123)              # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled['isFirstDown'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_o.drop(\"isFirstDown\",1)   #Feature Matrix\n",
    "y = df_o[\"isFirstDown\"]          #Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19957, 32)\n",
      "(8554, 32)\n",
      "(19957,)\n",
      "(8554,)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split # Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=72)\n",
    "\n",
    "numDimensions = X_test.shape[1]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 18) # Where to change the number of PCA variables\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07692646 0.07434848 0.0682184  0.05718669 0.05362752 0.05189172\n",
      " 0.04725129 0.04384966 0.0383857  0.03529685 0.03478507 0.03318251\n",
      " 0.03257513 0.03176543 0.02993404 0.02903532 0.02842683 0.02779567]\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)\n",
    "print (np.count_nonzero(explained_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   0\n",
      "1   0.07692645841424905\n",
      "2   0.15127493989347676\n",
      "3   0.21949333973173651\n",
      "4   0.27668003425897564\n",
      "5   0.3303075568414196\n",
      "6   0.3821992779198937\n",
      "7   0.42945056763533473\n",
      "8   0.47330022916236114\n",
      "9   0.5116859285443672\n",
      "10   0.5469827821109374\n",
      "11   0.5817678500487853\n",
      "12   0.6149503601783621\n",
      "13   0.6475254937779998\n",
      "14   0.6792909284462771\n",
      "15   0.7092249658096974\n",
      "16   0.7382602874139399\n",
      "17   0.7666871221190371\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,np.count_nonzero(explained_variance + 1)):\n",
    "    print(i,\" \", sum(explained_variance[0:i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "dtree = DecisionTreeClassifier(criterion=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Decision Tree Classifer\n",
    "dtree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "accText = 'Decision Tree, PCA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 72.31%\n",
      " Precision: 34.16%\n",
      "    Recall: 36.88%\n",
      "  F1 score: 35.47%\n",
      " ROC score: 59.20%\n",
      "      RMSE: 0.28\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = (accuracy_score(y_test, y_pred)).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('Accuracy',accuracy))\n",
    "# precision tp / (tp + fp)\n",
    "precision = (precision_score(y_test, y_pred)).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('Precision',precision))\n",
    "# recall: tp / (tp + fn)\n",
    "recall = (recall_score(y_test, y_pred)).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('Recall',recall))\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = (f1_score(y_test, y_pred)).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('F1 score',f1))\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = (auc(false_positive_rate, true_positive_rate)).astype('float64')\n",
    "print('{:>10}: {:0.2%}'.format('ROC score',roc_auc))\n",
    "# Root Mean Square Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = (mean_squared_error(y_test, y_pred)).astype('float64')\n",
    "print('{:>10}: {:0.2}'.format('RMSE',rmse))\n",
    "\n",
    "acc = pd.read_csv(\"../data/external/accuracies.csv\", index_col=0)\n",
    "acc.at[accText, 'Accuracy'] = (accuracy)\n",
    "acc.at[accText, 'Precision'] = (precision)\n",
    "acc.at[accText, 'Recall'] = (recall)\n",
    "acc.at[accText, 'F1'] = (f1)\n",
    "acc.at[accText, 'ROC'] = (roc_auc)\n",
    "acc.at[accText, 'RMSE'] = (rmse)\n",
    "acc.to_csv(\"../data/external/accuracies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[ 651 1114]\n",
      " [1255 5534]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      6789\n",
      "           1       0.34      0.37      0.35      1765\n",
      "\n",
      "    accuracy                           0.72      8554\n",
      "   macro avg       0.59      0.59      0.59      8554\n",
      "weighted avg       0.73      0.72      0.73      8554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Present Confusion Matrix to show accuracy\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred, labels=[1,0]))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(X_train)\n",
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.793664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.799977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.801964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.798340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.801964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.801613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.801263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.797405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.797288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.793664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.787702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.783259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.780337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.775777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.772855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.769581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.762684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.758242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.758826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.753799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.752280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.750643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.745733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.746551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.743395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.742226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.742927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.737082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.737433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.738017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.735562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.731003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   0.793664\n",
       "1   0.799977\n",
       "2   0.801964\n",
       "3   0.798340\n",
       "4   0.801964\n",
       "5   0.801613\n",
       "6   0.801263\n",
       "7   0.797405\n",
       "8   0.797288\n",
       "9   0.793664\n",
       "10  0.787702\n",
       "11  0.783259\n",
       "12  0.780337\n",
       "13  0.775777\n",
       "14  0.772855\n",
       "15  0.769581\n",
       "16  0.762684\n",
       "17  0.758242\n",
       "18  0.758826\n",
       "19  0.753799\n",
       "20  0.752280\n",
       "21  0.750643\n",
       "22  0.745733\n",
       "23  0.746551\n",
       "24  0.743395\n",
       "25  0.742226\n",
       "26  0.742927\n",
       "27  0.737082\n",
       "28  0.737433\n",
       "29  0.738017\n",
       "30  0.735562\n",
       "31  0.731003"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of values to try for max_depth:\n",
    "max_depth_range = list(range(1, numDimensions + 1))# List to store the average RMSE for each value of max_depth:\n",
    "accuracy = []\n",
    "for depth in max_depth_range:\n",
    "    \n",
    "    clf = DecisionTreeClassifier(max_depth = depth, random_state = 0)\n",
    "    clf.fit(X_train, y_train)    \n",
    "    score = clf.score(X_test, y_test)\n",
    "    accuracy.append(score)\n",
    "    \n",
    "pd.DataFrame(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
